---
description:
globs:
alwaysApply: false
---
# Supabase AI Starter Kit - Project Adaptation Guide

This rule helps me understand and guide users in adapting this Supabase AI Starter Kit for their specific AI applications and use cases.

## **Starter Kit Overview**

This is a comprehensive **Infrastructure-as-Code Supabase AI Starter Kit** that provides:

- **Full Supabase Backend**: Database, Auth, Realtime, Storage, Edge Functions
- **Kong API Gateway**: Professional API management and routing
- **n8n Workflow Automation**: AI workflow orchestration and integrations
- **Development Email**: Inbucket for testing email flows
- **Testing Infrastructure**: Postman collections and Node.js test scripts
- **Task Master Integration**: AI-powered project management
- **Docker-First Approach**: No Supabase Studio dependency, everything via config

## **Key Architecture Components**

### **Core Services** (docker-compose.yml)
- **`supabase-db`**: PostgreSQL with pgvector for AI embeddings
- **`supabase-auth`**: GoTrue authentication service
- **`supabase-kong`**: API gateway and routing (port 8000)
- **`supabase-rest`**: PostgREST API for database operations
- **`supabase-realtime`**: WebSocket connections for live updates
- **`supabase-storage`**: File storage service
- **`supabase-functions`**: Edge Functions runtime
- **`supabase-mail`**: Inbucket email service for development

### **AI/Automation Services**
- **`n8n`**: Workflow automation platform (port 5678)
- **n8n-postgres**: Dedicated database for n8n workflows

### **Development Tools**
- **Postman Collections**: Pre-configured API testing
- **Health Check Scripts**: Service monitoring
- **Test Authentication Scripts**: Complete auth flow testing

## **Common AI Use Cases & Adaptations**

### **ü§ñ AI Chatbot/Assistant**
**Typical Requirements:**
- User conversations storage
- Message history and context
- AI model integrations (OpenAI, Anthropic, etc.)
- Real-time messaging

**Adaptation Strategy:**
```sql
-- Example schema additions
CREATE TABLE conversations (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES auth.users(id),
  title TEXT,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE TABLE messages (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  conversation_id UUID REFERENCES conversations(id),
  role TEXT CHECK (role IN ('user', 'assistant', 'system')),
  content TEXT,
  metadata JSONB,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);
```

**n8n Workflows:**
- Chat completion workflow
- Message processing pipeline
- Context management

### **üìä AI Analytics/Insights Platform**
**Typical Requirements:**
- Data ingestion pipelines
- Vector embeddings for semantic search
- Dashboard APIs
- Scheduled AI analysis

**Adaptation Strategy:**
- Leverage pgvector for embeddings
- Create data ingestion n8n workflows
- Build analytics Edge Functions
- Use Realtime for live dashboard updates

### **üé® AI Content Generation**
**Typical Requirements:**
- Content templates and generation
- Media processing and storage
- Approval workflows
- Content versioning

**Adaptation Strategy:**
- Extend Supabase Storage for media
- Create generation workflows in n8n
- Build approval/review systems
- Version control with database schemas

### **üîç AI-Powered Search/Discovery**
**Typical Requirements:**
- Vector search capabilities
- Content indexing
- Search analytics
- Personalization

**Adaptation Strategy:**
- Utilize pgvector for semantic search
- Create indexing pipelines
- Build search analytics
- Implement user preference systems

## **Initialization Process for New Users**

### **Step 1: Environment Setup**
```bash
# Clone and setup
git clone <repository>
cd supabase-ai-starter-kit
cp .env.example .env
```

**Guide user to configure `.env` with:**
- Database credentials
- API keys for AI services (OpenAI, Anthropic, etc.)
- SMTP settings for development
- Custom domain/security settings

### **Step 2: Taskmaster Initialization**
```bash
# Initialize Taskmaster for project planning
npx task-master-ai init --rules cursor --name="My AI Project"
```

**Create PRD Strategy:**
1. **Interview Process**: Ask about their specific AI use case
2. **Requirements Gathering**: Technical stack, integrations, user flows
3. **PRD Creation**: Based on their responses, create comprehensive PRD
4. **Task Generation**: Use `parse-prd` to generate implementation roadmap

### **Step 3: Service Startup**
```bash
# Start core services
docker-compose up -d

# For development with email
docker-compose -f docker-compose.yml -f dev/docker-compose.dev.yml up -d

# Connect mail service to network (if needed)
docker network connect supabase_supastar supabase-mail
```

### **Step 4: Validation**
- Run health checks: `./scripts/health-check.sh`
- Test authentication: `node test-auth-complete.js`
- Verify n8n access: `http://localhost:5678`
- Check email service: `http://localhost:9000`

## **Extension Patterns**

### **Database Schema Extensions**
- **Start with authentication schema** (already configured)
- **Add domain-specific tables** based on use case
- **Leverage pgvector** for AI embeddings
- **Use JSONB fields** for flexible metadata
- **Implement RLS policies** for security

### **API Development Patterns**
- **Edge Functions** for AI processing (`volumes/functions/`)
- **PostgREST APIs** for CRUD operations
- **Kong routing** for API organization
- **Real-time subscriptions** for live features

### **n8n Workflow Patterns**
- **AI Model Integration**: OpenAI, Anthropic, local models
- **Data Processing Pipelines**: ETL for AI training
- **Webhook Handlers**: External service integrations
- **Scheduled Jobs**: Batch processing, cleanup tasks

### **Testing Strategy**
- **Postman Collections**: API endpoint testing
- **Node.js Scripts**: Authentication flow testing
- **Health Checks**: Service monitoring
- **Integration Tests**: End-to-end workflows

## **Common Configuration Points**

### **Authentication Customization**
```env
# Email settings
ENABLE_EMAIL_SIGNUP=true
ENABLE_EMAIL_AUTOCONFIRM=false  # Set true for development
DISABLE_SIGNUP=false

# OAuth providers (add as needed)
ENABLE_PHONE_SIGNUP=false
ENABLE_PHONE_AUTOCONFIRM=false
```

### **AI Service Integration**
```env
# Add AI service keys
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
HUGGING_FACE_API_KEY=hf_...
```

### **n8n Configuration**
```env
# n8n settings
N8N_BASIC_AUTH_ACTIVE=true
N8N_BASIC_AUTH_USER=admin
N8N_BASIC_AUTH_PASSWORD=password
```

## **Taskmaster Integration Strategy**

### **PRD Creation Process**
When helping users create their PRD, focus on:

1. **Use Case Definition**
   - Primary AI functionality
   - Target users and personas
   - Success metrics

2. **Technical Requirements**
   - AI models and APIs needed
   - Data storage requirements
   - Real-time features
   - Integration points

3. **Implementation Phases**
   - MVP features (authentication + core AI)
   - Advanced features (analytics, optimization)
   - Scaling considerations

### **Task Generation Strategy**
- **Phase 1**: Core setup and basic AI functionality
- **Phase 2**: User interface and experience
- **Phase 3**: Advanced features and optimizations
- **Phase 4**: Testing, deployment, and monitoring

### **Common Task Categories**
- **Infrastructure**: Database schema, API setup
- **AI Integration**: Model connections, processing pipelines
- **User Experience**: Authentication, UI/UX, real-time features
- **Testing**: Unit tests, integration tests, load testing
- **Deployment**: Production setup, monitoring, CI/CD

## **Key Success Patterns**

### **üöÄ Quick Start Wins**
1. **Get authentication working first** (already configured)
2. **Create simple AI endpoint** (Edge Function + n8n workflow)
3. **Build basic UI** for testing AI functionality
4. **Add real-time features** for better UX

### **üèóÔ∏è Scalable Architecture**
- **Separate concerns**: Auth, AI processing, data storage
- **Use Kong for API management** as complexity grows
- **Leverage n8n for complex workflows** vs Edge Functions for simple APIs
- **Plan for vector search early** if relevant to use case

### **üîß Development Best Practices**
- **Test early and often** with provided test scripts
- **Use Postman collections** for API development
- **Monitor services** with health checks
- **Version control workflows** in n8n export format

## **Red Flags & Common Issues**

### **‚ö†Ô∏è Networking Issues**
- **Docker network connectivity**: Ensure services can communicate
- **Port conflicts**: Check for existing services on required ports
- **Environment variables**: Verify all required keys are set

### **‚ö†Ô∏è Authentication Problems**
- **Email confirmation**: Configure SMTP properly for production
- **CORS issues**: Set up allowed origins correctly
- **JWT secrets**: Use strong, unique secrets in production

### **‚ö†Ô∏è AI Integration Challenges**
- **API rate limits**: Plan for quota management
- **Model costs**: Monitor usage and implement budgets
- **Context windows**: Design for token limitations
- **Error handling**: Graceful degradation when AI services fail

## **Questions to Ask New Users**

### **Use Case Discovery**
1. "What specific AI functionality do you want to build?"
2. "Who are your target users and how will they interact with the AI?"
3. "What data will your AI work with?"
4. "Do you need real-time features or can it be request/response?"

### **Technical Requirements**
1. "Which AI models/services do you plan to use?"
2. "Do you need vector search or semantic similarity?"
3. "Will you have user-generated content or workflows?"
4. "What integrations with external services do you need?"

### **Scope and Timeline**
1. "What's your MVP vs. full feature set?"
2. "Do you have any existing systems to integrate with?"
3. "What's your experience level with these technologies?"
4. "Any specific deployment or scaling requirements?"

## **Helpful Commands Reference**

### **Development Workflow**
```bash
# Start services
docker-compose up -d

# View logs
docker-compose logs -f [service-name]

# Reset and clean restart
./reset.sh

# Health check
./scripts/health-check.sh

# Test authentication
node test-auth-complete.js
```

### **Taskmaster Commands**
```bash
# Initialize project
task-master init --rules cursor

# Parse requirements
task-master parse-prd requirements.txt

# Get next task
task-master next

# Update progress
task-master update-subtask --id=X.Y --prompt="Progress update"
```

This starter kit provides a production-ready foundation for AI applications with Supabase. The key is helping users understand which components to extend vs. replace based on their specific use case, and creating a clear implementation roadmap through Taskmaster.
